# README

### This is an anonymous repository for the paper "FLED: Fine-Grained Poisoning Attacks for Accurate Sub-Optimal Traps". We have provided a simple demonstration of FLED on the CIFAR10 dataset.

### It aims to launch precise model poisoning attacks (MPAs) in federated learning. The main data directory shall be as follows:


#### Test:

- run **FMPA.py ** for attacking federated learning.


#### Dependencies:

python==3.6.13

pytorch==1.10.2

torchvision==0.9.0

numpy==1.19.5

pandas==1.1.5

pickleshare==0.7.4